
# ===============================================
# recommendation_artist.py
# ===============================================
import pickle
import pandas as pd
from pymongo import MongoClient
from scipy.sparse import csr_matrix
import os

# --- K·∫æT N·ªêI DATABASE ---
client = MongoClient("mongodb://localhost:27017/")
db = client["moo_d"]

# --- T·∫¢I M√î H√åNH CF (ƒë√£ train s·∫µn t·ª´ Colab) ---
base_dir = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(base_dir, "models/model_artist.pkl")
pivot_path = os.path.join(base_dir, "models/pivot_artist.pkl")

try:
    model_artist = pickle.load(open(model_path, "rb"))
    pivot_artist = pickle.load(open(pivot_path, "rb"))
    pivot_sparse = csr_matrix(pivot_artist.values)
    print("‚úÖ M√¥ h√¨nh Recommended Artist ƒë√£ s·∫µn s√†ng.")
except Exception as e:
    print("‚ö†Ô∏è L·ªói khi t·∫£i model CF:", e)
    model_artist = pivot_artist = pivot_sparse = None

# -------------------------
# 3Ô∏è‚É£ H√ÄM FALLBACK CHO USER M·ªöI
# -------------------------
def get_popular_artists(top_n=10):
    """
    D√†nh cho user m·ªõi (ch∆∞a c√≥ l·ªãch s·ª≠ nghe)
    ‚Üí G·ª£i √Ω ngh·ªá sƒ© ƒë∆∞·ª£c nghe nhi·ªÅu nh·∫•t to√†n h·ªá th·ªëng.
    """
    try:
        user_history = pd.DataFrame(list(db.user_history.find({}, {"artistName": 1, "_id": 0})))
        if user_history.empty:
            return []

        # ‚úÖ S·ª¨A: ƒê∆°n gi·∫£n h√≥a logic tr√°nh duplicate columns
        pop = (
            user_history["artistName"]
            .value_counts()
            .head(top_n)
            .reset_index()
        )

        # ‚úÖ ƒê·∫∑t t√™n c·ªôt r√µ r√†ng
        pop.columns = ["artist", "count"]
        pop["type"] = "üî• Popular"

        return pop[["artist", "type"]].to_dict(orient="records")

    except Exception as e:
        print("‚ùå L·ªói khi t·∫°o fallback:", e)
        return []


# -------------------------
# 4Ô∏è‚É£ H√ÄM G·ª¢I √ù CH√çNH (THEO LOGIC CELL ‚ë¢)
# -------------------------
def recommend_for_user(user_id, top_n=8, n_neighbors=60, months_back=3, verbose=False):
    """
    G·ª£i √Ω ngh·ªá sƒ© cho user d·ª±a tr√™n l·ªãch s·ª≠ nghe + CF + ƒëa d·∫°ng h√≥a
    (b·∫£n t∆∞∆°ng ƒë∆∞∆°ng logic v·ªõi Cell ‚ë¢ - nh∆∞ng d√πng MongoDB)
    """
    try:
        if model_artist is None or pivot_artist is None:
            print("Model ch∆∞a ƒë∆∞·ª£c load.")
            return get_popular_artists(top_n)

        # --- L·∫•y d·ªØ li·ªáu t·ª´ MongoDB ---
        history_all = pd.DataFrame(list(db.user_history.find({}, {"userId": 1, "artistName": 1, "PlayCount": 1, "LastPlayedAt": 1, "_id": 0})))
        if history_all.empty:
            return get_popular_artists(top_n)

        history_all["LastPlayedAt"] = pd.to_datetime(history_all["LastPlayedAt"], errors="coerce")
        history_all = history_all.dropna(subset=["LastPlayedAt"])

        # D·ªØ li·ªáu ri√™ng c·ªßa user
        user_hist = history_all[history_all["userId"] == str(user_id)]
        if user_hist.empty:
            if verbose: print(f"üßä User {user_id} ch∆∞a c√≥ l·ªãch s·ª≠ nghe ‚Üí fallback.")
            return get_popular_artists(top_n)

        # --- Ph·∫ßn 1: L·∫•y l·ªãch s·ª≠ 3 th√°ng g·∫ßn nh·∫•t ---
        latest_date = user_hist["LastPlayedAt"].max()
        cutoff_date = latest_date - pd.DateOffset(months=months_back)
        recent_df = user_hist[user_hist["LastPlayedAt"] >= cutoff_date]
        if recent_df.empty:
            recent_df = user_hist

        top_recent_artists = recent_df["artistName"].value_counts().head(10).index.tolist()
        recent_artists_set = set(recent_df["artistName"].value_counts().head(50).index.tolist())

        if verbose:
            print(f"üéß Top ngh·ªá sƒ© {user_id} nghe g·∫ßn ƒë√¢y: {top_recent_artists}")

        # --- Ph·∫ßn 2: Candidate retrieval (CF-based) ---
        recs = []
        for idx, artist in enumerate(top_recent_artists[:3]):
            if artist not in pivot_artist.columns:
                continue
            idx_col = pivot_artist.columns.get_loc(artist)
            dist, ind = model_artist.kneighbors(pivot_sparse.T[idx_col], n_neighbors=n_neighbors + 1)
            weight = 1 - (idx * 0.15)
            for d, i in zip(dist[0][1:], ind[0][1:]):
                recs.append({"artist": pivot_artist.columns[i], "sim": 1 - d, "weight": weight})

        if not recs:
            if verbose: print(f"‚ö†Ô∏è Kh√¥ng t·∫°o ƒë∆∞·ª£c g·ª£i √Ω cho user {user_id}.")
            return get_popular_artists(top_n)

        rec_df = pd.DataFrame(recs)
        rec_df["weighted_sim"] = rec_df["sim"] * rec_df["weight"]
        rec_df = rec_df.groupby("artist", as_index=False)["weighted_sim"].sum()

        # --- Ph·∫ßn 3: T√≠nh tr·ªçng s·ªë ƒëa d·∫°ng ---
        artist_freq = history_all["artistName"].value_counts(normalize=True)
        rec_df["global_freq"] = rec_df["artist"].map(artist_freq).fillna(0)
        rec_df["diversity_weight"] = 1 / (1 + 5 * rec_df["global_freq"])

        # --- Ph·∫ßn 4: T√≠nh ƒëi·ªÉm t·ªïng h·ª£p ---
        rec_df["final_score"] = rec_df["weighted_sim"]
        rec_df["discovery_score"] = rec_df["final_score"] * rec_df["diversity_weight"]

        # --- Ph·∫ßn 5: Chia nh√≥m Quen / M·ªõi ---
        # top_recent_set = set(recent_df["artistName"].value_counts().head(10).index.tolist())
        # familiar_candidates = (
        #     rec_df[rec_df["artist"].isin(top_recent_set)]
        #     .sort_values("final_score", ascending=False)
        #     .head(5)
        # )
        # new_candidates = (
        #     rec_df[~rec_df["artist"].isin(recent_artists_set)]
        #     .sort_values("discovery_score", ascending=False)
        #     .head(3)
        # )
        #
        # # Fallback n·∫øu thi·∫øu ngh·ªá sƒ© m·ªõi
        # if len(new_candidates) < (top_n - 5):
        #     fallback = (
        #         rec_df[~rec_df["artist"].isin(top_recent_set)]
        #         .sort_values("discovery_score", ascending=False)
        #         .head(top_n - len(familiar_candidates))
        #     )
        #     new_candidates = pd.concat([new_candidates, fallback]).drop_duplicates("artist").head(top_n - len(familiar_candidates))
        # --- Ph·∫ßn 5: Chia nh√≥m Quen / M·ªõi (S·ª¨A L·∫†I HO√ÄN TO√ÄN) ---
        top_recent_set = set(recent_df["artistName"].value_counts().head(10).index.tolist())

        print(f"üîç DEBUG: rec_df c√≥ {len(rec_df)} candidates tr∆∞·ªõc khi filter")
        print(f"üîç DEBUG: top_recent_set c√≥ {len(top_recent_set)} artists")

        # üéØ S·ª¨A: L·∫•y TOP top_n artists t·ª´ rec_df, KH√îNG ph√¢n chia familiar/new
        hybrid_df = rec_df.sort_values("final_score", ascending=False).head(top_n * 2)  # L·∫•y d∆∞ ƒë·ªÉ filter

        # üéØ G√°n type d·ª±a tr√™n c√≥ trong top_recent_set hay kh√¥ng
        hybrid_df["type"] = hybrid_df["artist"].apply(
            lambda a: "‚≠ê Familiar (CF)" if a in top_recent_set else "üå± New (Diversity)"
        )

        # üéØ ƒê·∫£m b·∫£o c√≥ s·ª± c√¢n b·∫±ng (√≠t nh·∫•t 2-3 artists m·ªõi)
        familiar_count = sum(hybrid_df["type"] == "‚≠ê Familiar (CF)")
        new_count = sum(hybrid_df["type"] == "üå± New (Diversity)")

        print(f"üîç DEBUG: familiar_count: {familiar_count}, new_count: {new_count}")

        # üéØ N·∫øu kh√¥ng ƒë·ªß artists m·ªõi, ƒëi·ªÅu ch·ªânh
        if new_count < 3 and len(rec_df) > top_n:
            # L·∫•y th√™m artists m·ªõi t·ª´ ph·∫ßn c√≤n l·∫°i c·ªßa rec_df
            remaining_new = rec_df[~rec_df["artist"].isin(hybrid_df["artist"]) &
                                   ~rec_df["artist"].isin(top_recent_set)]
            remaining_new = remaining_new.sort_values("discovery_score", ascending=False).head(3 - new_count)

            if len(remaining_new) > 0:
                remaining_new["type"] = "üå± New (Diversity)"
                hybrid_df = pd.concat([hybrid_df, remaining_new]).drop_duplicates("artist")
                hybrid_df = hybrid_df.sort_values("final_score", ascending=False).head(top_n)

        # üéØ C·∫Øt ch√≠nh x√°c top_n
        hybrid_df = hybrid_df.head(top_n)

        print(f"‚úÖ FINAL: C√≥ {len(hybrid_df)} recommendations")
        for _, row in hybrid_df.iterrows():
            print(f"   - {row['artist']} ({row['type']})")

        return hybrid_df[["artist", "type", "final_score", "discovery_score"]].to_dict(orient="records")

        # --- Ph·∫ßn 6: G·ªôp k·∫øt qu·∫£ ---
        hybrid_df = pd.concat([familiar_candidates, new_candidates]).drop_duplicates("artist")
        hybrid_df["type"] = hybrid_df["artist"].apply(
            lambda a: "‚≠ê Familiar (CF)" if a in top_recent_set else "üå± New (Diversity)"
        )

        hybrid_df = hybrid_df.sort_values("final_score", ascending=False).head(top_n)
        return hybrid_df[["artist", "type", "final_score", "discovery_score"]].to_dict(orient="records")

    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫°o g·ª£i √Ω cho user {user_id}: {e}")
        return get_popular_artists(top_n)